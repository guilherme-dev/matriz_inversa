\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{float}

\usepackage{mathtools}

\usepackage{graphicx,url}

\usepackage[brazil]{babel}
%\usepackage[latin1]{inputenc}
\usepackage[utf8]{inputenc}
% UTF-8 encoding is recommended by ShareLaTex
\usepackage{verbatim}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{fancyref}

\usepackage{fancyhdr}
\fancyhf{}
\cfoot{\thepage}
\pagestyle{fancy}

\definecolor{verde}{rgb}{0,0.5,0}

%para customizar o código (ver https://en.wikibooks.org/wiki/LaTeX/Source_Code_Listings)
\lstset{language=C, %defina a linguagem usada no trabalho
              belowcaptionskip=1\baselineskip,
                breaklines=true,
                frame=false,
                xleftmargin=\parindent,
                showstringspaces=false,
                basicstyle=\footnotesize\ttfamily,
                keywordstyle=\bfseries\color{green!40!black},
                commentstyle=\itshape\color{purple!40!black},
                identifierstyle=\color{blue},
                stringstyle=\color{orange},
                numbers=left,
            }

\sloppy

\title{Otimização do Desempenho na Inversão de Matrizes\\ Universidade Federal do Paraná}

\author{Guilherme Gomes dos Santos\inst{1}}


\address{Bacharelado em Ciência da Computação -- Universidade Federal do Paraná (UFPR)
%\nextinstitute
%  Department of Computer Science -- University of Durham\\
%  Durham, U.K.
%\nextinstitute
 % Departamento de Sistemas e Computação\\
  %Universidade Regional de Blumenal (FURB) -- Blumenau, SC -- Brazil
  \email{ggs12@inf.ufpr.br}
}

\begin{document}

\maketitle

\begin{resumo}
 O trabalho prático da disciplina Introdução à Computação Científica é dividido em duas partes. Na primeira, foi desenvolvido um algoritmo na linguagem C que calculava a inversa de uma matriz, utilizando fatoração LU com pivotamento parcial e refinamento sucessivo. Na segunda parte do trabalho, efetuou-se melhorias no código com o objetivo de melhorar seu desempenho. Este documento apresenta os resultados obtidos após estas otmizações.
\end{resumo}

\section{Introdução}
Durante a primeira etapa do trabalho prático (\textbf{v1}), foi desenvolvido um programa computacional em linguagem C que, dada uma matriz quadrada A de dimensão $n$, devolve a matriz inversa de ${A}$ (${A}^{-1}$), tal que $A {A}^{-1} = I$, onde ${I}$ é a matriz identidade. O algoritmo desenvolvido utiliza eliminação de Gauss com pivotamento parcial, fatoração LU e refinamento sucessivo.

Para a segunda etapa do trabalho (\textbf{v2}), dois trechos do código foram otimizadas de forma a obter uma melhora de desempenho durante a execução do método:
\begin{itemize}
\item Na operação de resolução do sistema linear triangular (\textbf{op1}): $Ly = b; Ux = y$;
\item Na operação de cálculo do resíduo (\textbf{op2}): $R = I - A{A}^{-1}$;
\end{itemize}

Os testes de desempenho foram executados utilizando a ferramenta {Likwid}$^{[1]}$, analisando os seguintes aspectos: Tempo médio do cálculo da \textbf{op1} e tempo médio do cálculo da \textbf{op2}, banda de memória (Memory bandwidth [MBytes/s]) do grupo L3, cache miss (data cache miss ratio) do grupo L2 e operações aritméticas (MFLOP/s) do grupo FLOPS\_DP.

A arquitetura do computador utilizado durante os testes de otimização, obtida através da ferramenta likwid-topology, é exibida abaixo:


\begin{table}[H]
\centering
\caption{Processador}
\label{my-label}
\begin{tabular}{ll}
CPU name         & Intel(R) Core(TM) i7-3610QM CPU @ 2.30GHz \\
CPU type         & Intel Core IvyBridge processor            \\
CPU stepping     & 9                                       \\ \hline
Sockets          & 1                                       \\
Cores per socket & 4                                       \\
Threads per core & 2
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Cache Topology}
\label{my-label}
\begin{tabular}{ll}
Level        & 1                              \\
Size         & 32 kB                          \\
Associativity: & 8                            \\
Cache line size: &  64                        \\\hline
Level        & 2                              \\
Size         & 256 kB                         \\
Associativity: & 8                            \\
Cache line size: &  64                        \\\hline
Level        & 3                              \\
Size         & 6 MB                           \\
Associativity: & 12                           \\
Cache line size: &  64                        \\
\end{tabular}
\end{table}

\section{Estrutura dos dados} \label{sec:firstpage}

Para a primeira etapa do trabalho todas as matrizes foram armazenadas em vetores unidimensionais, visando alocação de memória contígua. Os vetores contendo as matrizes $L$ e $U$ apresentavam as seguintes estruturas:

$L$:

$$ \left(
  \begin{array}{c c c c c}
     1       & 0      & 0      & 0      & 0\\
     l_{10}  & 1      & 0      & 0      & 0\\
     l_{20}  & l_{21} & 1      & 0      & 0\\
     l_{30}  & l_{31} & l_{32} & 1      & 0\\
     l_{40}  & l_{41} & l_{42} & l_{43} & 1 \\
  \end{array} \right)
$$

$U$:

$$ \left(
  \begin{array}{c c c c c}
     u_{00}  & u_{01}    & u_{02} & u_{03}  & u_{04}\\
     0       & u_{11}    & u_{12} & u_{13}  & u_{14}\\
     0       & 0         & u_{22} & u_{23}  & u_{24}\\
     0       & 0         & 0      & u_{33}  & u_{34}\\
     0       & 0         & 0      & 0       & u_{44} \\
  \end{array} \right)
$$

Observa-se que armazenar o conteúdo desta forma é ineficiente, uma vez que todos os zeros das matrizes não são utilizados durante a execução do método.

\section{Otimizações}
\subsection{Estrutura de dados}
O primeiro objetivo durante a \textbf{v2} foi criar estruturas para armazenar estas matrizes de maneira mais eficiente, evitando o desperdício de memória e acesso não contínuo aos dados. As tabelas 3 e 4 demonstram a maneira encontrada para armazenar as matrizes $L$ e $U$.

\begin{table}[H]
\centering
\caption{Matriz L: Vetor melhorado}
\label{my-label}
\begin{tabular}{l|l|l|l|l|l|l|l|l|l|l|}
\cline{2-11}
i   & 0      & 1      & 2      & 3      & 4      & 5      & 6      & 7      & 8      & 9   \\ \cline{2-11}
L[i] & $l_{10}$ & $l_{20}$ & $l_{21}$ & $l_{30}$ & $l_{31}$ & $l_{32}$ & $l_{40}$ & $l_{41}$ & $l_{42}$ & $l_{43}$ \\ \cline{2-11}
\end{tabular}
\end{table}

\begin{table}[H]
\caption{Matriz U: Vetor melhorado}
\label{my-label}
\begin{tabular}{l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|l|}
\cline{2-16}
i   & 0      & 1      & 2      & 3      & 4      & 5      & 6      & 7      & 8      & 9   & 10  & 11  & 12  & 13  & 14 \\ \cline{2-16}
U[i] & $u_{00}$ & $u_{01}$ & $u_{02}$ & $u_{03}$ & $u_{04}$ & $u_{11}$ & $u_{12}$ & $u_{13}$ & $u_{14}$ & $u_{22}$ & $u_{23}$ & $u_{24}$ & $u_{33}$ & $u_{34}$ & $u_{44}$ \\ \cline{2-16}
\end{tabular}
\end{table}

A primeira versão da estrutura de dados, apresentada na\textbf{v1} do código, não é eficiente pois além de armazenar dados desnecessários, gera um acesso não linear aos elementos da matriz: O acesso é organizado em linhas de cache, que são carregadas de uma única vez. Assim, ao acessar o elemento $l_{10}$ por exemplo, os elementos seguintes da mesma linha da matriz L são trazidos dentro da linha de cache. O próximo elemento a ser acessado é o $l_{20}$, que não estará na cache (para um tamanho de linha da matriz suficientemente grande), gerando assim um cache miss.

Assim, ao alinhar os dados nas estruturas descritas os próximos elementos a serem acessados estão sempre na mesma (ou próxima) linha de cache, já que são alocados de maneira contígua. Além disso, consequentemente o tamanho dos vetores é menor: $|L| = (n * (n+1)) / 2 - n$ e $|U| = (n * (n+1)) / 2$ .


\subsection{Código}

Para otimizar as estruturas de dados das matrizes $L$ e $U$ foi necessário criar um novo método de percorrer os vetores. Isso ocorre pois cada linha da matriz possui um tamanho diferente, gerando a necessidade de cálculos de índices. Além disso, outra dificuldade surge: o pivotamento parcial executa trocas de linhas nas matrizes $L$ e $U$.

Como a dificuldade para implementar um algoritmo que efetuase estas trocas de linhas em cima dos vetores otimizados seria grande, a decisão foi de manter matrizes auxiliares L\_aux e U\_aux (vetores de dimensão $n * n$) para se efetuar a decomposição LU. Esta alternativa tira proveito do fato de que a eliminação de Gauss com pivotamento parcial é executada apenas uma vez durante o método.

O código abaixo é executado após a conclusão do pivotamento parcial, no qual se efetua uma cópia dos valores úteis contidos nos vetores auxiliares L\_aux e U\_aux para os vetores otimizados L e U.

\begin{lstlisting}
    // Inicializa o vetor alinhado L com os valores da matrix inferior
    for (i = 0; i < N; i++ ) {
        for (j = 0; j < i; j++) {
            L[index(i,j)] = L_aux[i*N+j];
        }
    }

    // Inicializa o vetor alinhado U com os valores da matrix superior
    for (i = 0; i < N; ++i) {
        for (j = i; j < N; ++j) {
            U[uindex(i,j,N)] = U_aux[i*N+j];
        }
    }
\end{lstlisting}

Observa-se que ainda que adicionando esta cópia de dados ao código obtenha-se um ganho em desempenho, e isso é possível por a eliminação de Gauss é executada uma vez, enquanto os vetores L e U serão utilizados $número de iterações * n$ vezes.

Como cada linha dos vetores L e U possui uma dimensão diferente, foi necessário criar as seguintes macros para que a indexação dos vetores fosse feita de maneira simples:

\begin{lstlisting}
#define size(n) (((n)*(n+1))/2)
#define offset(i,j) (size((i)-1)+(j))
#define index(i,j) ((i)<(j) ? 0 :  (offset((i),(j))))
#define uindex(i,j,n) ((i)>(j) ? 0 : (size(n)-size((n)-(i))+(j)-(i)))

//Acessar L[i,j] : L[index(i,j)]
//Acessar U[i,j] : U[uindex(i,j,N)]
\end{lstlisting}



\subsection{Versão sem desvios condicionais}
Um dos pontos citados, pelo professor, na entrega da 1ª versão é a importância de evitar desvios condicionais, ainda mais dentro de laços. Com isso em mente, a primeira otimização foi justamente essa substituição de desvios por \textit{loops}.
\begin{lstlisting}
for(i=0; i< k ; i++){
    resultado[i] = 0;
    //Bloco 1
    for(j=0; j< i; j++)
       resultado[i] += a[(j*(k+1))+(i-j)]*b[j];
    //Bloco 2
    for(; j <= k+i; j++)
        resultado[i] += a[(i*(k+1))+(j-i)]*b[j];
}

for(; i< N-k ; i++){
    //Bloco 3
    for(j=i-k; j< i; j++)
        resultado[i] += a[(j*(k+1))+(i-j)]*b[j];
    //Bloco 4
    for(; j <= k+i; j++)
        resultado[i] += a[(i*(k+1))+(j-i)]*b[j];
}

for(; i< N ; i++){
    //Bloco 5
    for(j=i-k; j< i; j++)
        resultado[i] += a[(j*(k+1))+(i-j)]*b[j];
    //Bloco 6
    for(; j < N; j++)
        resultado[i] += a[(i*(k+1))+(j-i)]*b[j];
}
\end{lstlisting}

\begin{itemize}
\item Bloco 1: percorre as posições da matriz do lado que não é armazenado no vetor(a esquerda da diagonal principal) e começa sempre do primeiro elemento da linha até a diagonal principal.
\item Bloco 2: percorre as posições da matriz do lado que é armazenado no vetor e começa sempre da diagonal principal até o último elemento da linha diferente de \textit{zero}, complementando o \textit{Bloco 1}.
\item Bloco 3 e 4: percorrem as linhas da matrizes que não precisam se preocupar com as laterais, isso significa que as linhas possuem elementos diferentes de \textit{zero} iguais ao número de banda.
\item Bloco 5: percorre as posições da matriz do lado que não é armazenado no vetor(a esquerda da diagonal principal) e começam sempre do primeiro elemento da linha diferente de \textit{zero} até a diagonal principal.
\item Bloco 6: percorre as posições da matriz do lado que é armazenado no vetor e começa sempre da diagonal principal até o último elemento da linha, complementando o \textit{Bloco 5}.
\end{itemize}
Os blocos 1, 2, 5 e 6, diferentes dos blocos 3 e 4, precorrem linhas da matriz nas quais o número de elementos diferentes de \textit{zero} é menor do que o número de bandas.


\subsection{Versão com AVX}
\begin{lstlisting}
for(i=0; i< k ; i++){
    resultado[i] = 0;
    //Bloco 1
    int mod = i%4;
    for(j=0; j<mod; ++j){
        resultado[i] += a[(j*(k+1))+(i-j)]*b[j];
    }
    for(j=mod; j<i; j=j+4){
        aAVX = _mm256_set_pd(a[((j+3)*(k+1))+(i-(j+3))],
                             a[((j+2)*(k+1))+(i-(j+2))],
                             a[((j+1)*(k+1))+(i-(j+1))],
                             a[(j*(k+1))+(i-j)]);
        bAVX = _mm256_loadu_pd(&(b[j]));
        auxAVX = _mm256_mul_pd(aAVX, bAVX);
        resultado[i] += auxAVX[0] + auxAVX[1] + auxAVX[2]
                      + auxAVX[3];
    }

    //Bloco 2
    mod = (k+i+1)%4;
    for(j=i; j<(i+mod); ++j){
        resultado[i] += a[(i*(k+1))+(j-i)]*b[j];
    }
    for(j=(i+mod); j<=k+i; j=j+4){
        aAVX = _mm256_set_pd(a[(i*(k+1))+((j+3)-i)],
                             a[(i*(k+1))+((j+2)-i)],
                             a[(i*(k+1))+((j+1)-i)],
                             a[(i*(k+1))+(j-i)]);
        bAVX = _mm256_loadu_pd(&(b[j]));
        auxAVX = _mm256_mul_pd(aAVX, bAVX);
        resultado[i] += auxAVX[0] + auxAVX[1] + auxAVX[2]
                      + auxAVX[3];
    }
}

...

    //Bloco 6
    mod = N%4;
    for(j=i; j <(i+mod); ++j){
        resultado[i] += a[(i*(k+1))+(j-i)]*b[j];
    }
    for(j=(i+mod); j<N; j=j+4){
        aAVX = _mm256_set_pd(a[(i*(k+1))+((j+3)-i)],
                             a[(i*(k+1))+((j+2)-i)],
                             a[(i*(k+1))+((j+1)-i)],
                             a[(i*(k+1))+(j-i)]);
        bAVX = _mm256_loadu_pd(&(b[j]));
        auxAVX = _mm256_mul_pd(aAVX, bAVX);
        resultado[i] += auxAVX[0] + auxAVX[1] + auxAVX[2]
                      + auxAVX[3];
    }
}
\end{lstlisting}

A versão em AVX possui a mesma abordagem nos blocos, ou seja, cada um continua com a mesma função, a diferença é que neste versão todas as operação são feitas com instruções AVX para melhorar o desempenho. Sendo assim, como os registradores AVX possuem 256 bits e os valores utilizados por nós possuem 64 bits, nós conseguimos paralelizar quatro operações, por isso fazemos com que a cada \textit{loop} do segundo laço de cada bloco avance de quatro em quatro unidades (\textit{j=j+4}). O primeiro laço de cada bloco existe pois nem sempre o número de iterações deste será múltiplo de quatro, por isso, sempre antes de começarem as operações, nós dividimos o número de iterações totais do bloco por quatro a fim de obter o resto desta divisão. Esse resto vai ser a quantidade de iterações realizadas no primeiro laço.

\section{Análise de dados e gráficos}\label{sec:analisedosdados}
\subsection{Flops AVX}\label{sec:analisedosdados}

\begin{figure}[H]
\centering
\includegraphics[width=.7\textwidth]{img/FLOPSAVX7.png}
\caption{Flops\_AVX - 7 bandas}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=.7\textwidth]{img/FLOPS_AVX_27.png}
\caption{Flops\_AVX - 27 bandas}
\end{figure}

O teste de operações aritméticas, grupo FLOPS\_AVX, nos disponibiliza os valores da taxa de operações aritméticas com valores em ponto flutuante, em MFLOP/s. Visto que, tanto na multiplicação de vetor por vetor quanto na multiplicação de matriz por vetor, todas as operações são em ponto flutuante, então é muito importante que esta taxa seja alta para que o desempenho seja bom. Ao analisarmos os gráficos obtidos, vemos que houve um crescimento desta taxa na 2ª versão, mostrando que o desempenho da aplicação está bem melhor e mais otimizado.

\subsection{L2CACHE - Cache Miss}\label{sec:analisedosdados}

\begin{figure}[H]
\centering
\includegraphics[width=.7\textwidth]{img/L2CACHE7.png}
\caption{Cache Miss Ratio - 7 bandas}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=.7\textwidth]{img/L2CACHE27.png}
\caption{Cache Miss Ratio - 27 bandas}
\end{figure}

O teste de \textit{cache miss}, grupo L2CACHE, nos disponibiliza os valores da taxa de \textit{cache misses} da L2 durante a execução de determinado trecho do código. Ao analisarmos os gráficos obtidos, percebemos que não houve uma melhoria neste quesito da primeira versão para a segunda versão. Isto ocorreu pois o método de armazenamento na 1ª e na 2ª versão foram conservados, a otimização ocorreu apenas nas execuções das multiplicações.

\subsection{L3 - Banda de Memória}

\begin{figure}[H]
\centering
    \includegraphics[width=.7\textwidth]{img/L37.png}
    \caption{L3 - 7 bandas}
\end{figure}

\begin{figure}[H]
\centering
    \includegraphics[width=.7\textwidth]{img/L327.png}
    \caption{L3 - 27 bandas}
\end{figure}

O teste de banda de memória, grupo L3, nos disponibiliza os valores da taxa de transferência de dados entre a memória e o processador, em MBytes/s. Como nossa aplicação é para cálculos científicos, esta troca de dados entre memória e processador é muito intensa, e quanto maior a taxa, mais dados estão sendo transmitidos, consequentemente o desempenho da aplicação se torna maior. Ao analisarmos os gráficos obtidos, vemos que houve uma melhora nesta taxa na 2ª versão da aplicação, e um dos motivos para isso é a paralelização das operações que as instruções AVX possibilitam.

\subsection{Tempo de Execução}

\begin{figure}[H]
\centering
    \includegraphics[width=.7\textwidth]{img/TIME7.png}
    \caption{Tempo - 7 bandas}
\end{figure}

\begin{figure}[H]
\centering
    \includegraphics[width=1\textwidth]{img/TIME27.png}
    \caption{Tempo - 27 bandas}
\end{figure}

Um dos critérios mais significativos para comprovar a otimização do algoritmo é a melhora no tempo de execução, mesmo não sendo uma diferença gritante, ficou claro que além do método todo, o tempo para executar as multiplicação foram reduzidos. Notando que na 1ª versão, ao aumentar a quantidade de bandas de 7 para 27 o tempo aumentou muito mais que na 2ª versão, consequentemente o aumento das bandas já não afeta mais tanto o desempenho do algoritmo.

\section{Considerações Finais e Conclusão}

A primeira etapa do trabalho consistia em implementar o método do \textit{Gradiente Conjugado}. Por conta da complexidade dos testes, fizemos otimizações já na primeira versão, isso inclui o método de armazenamento que adotamos atualmente, a parte difícil é a indexação para multiplicar por um vetor. Na primeira versão foi usado \textit{desvios condicionais} e na segunda foi usado \textit{loops} separados. A otimização se torna mais clara nos momentos em que o tempo de execução é decaído, sendo assim, durante o processo de aperfeiçoamento, este tempo foi um dos fatores no qual mais nos baseamos. Grande parte dos nossos estudos e dedicação nesta segunda etapa do trabalho foi a otimização da multiplicação de matriz por vetor, visto que a função ficou bem extensa devido ao número de laços, porém através do \textit{loop unrolling} e da implementação das instruções AVX, obtivemos um resultado bem satisfatório.

\end{document}
